{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.9/site-packages (4.5.2.54)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.9/site-packages (from opencv-python) (1.20.3)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: pypylon in /opt/conda/lib/python3.9/site-packages (1.7.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: pypylon-opencv-viewer in /opt/conda/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.9/site-packages (from pypylon-opencv-viewer) (7.6.3)\n",
      "Requirement already satisfied: pypylon in /opt/conda/lib/python3.9/site-packages (from pypylon-opencv-viewer) (1.7.2)\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.9/site-packages (from pypylon-opencv-viewer) (1.0.0)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.9/site-packages (from pypylon-opencv-viewer) (7.24.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (5.0.9)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (0.18.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (49.6.0.post20210108)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (3.0.18)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (5.0.5)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (0.1.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.9/site-packages (from ipython->pypylon-opencv-viewer) (2.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython->pypylon-opencv-viewer) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython->pypylon-opencv-viewer) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->pypylon-opencv-viewer) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.9/site-packages (from traitlets>=4.2->ipython->pypylon-opencv-viewer) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets->pypylon-opencv-viewer) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets->pypylon-opencv-viewer) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets->pypylon-opencv-viewer) (1.0.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets->pypylon-opencv-viewer) (5.5.5)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->pypylon-opencv-viewer) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->pypylon-opencv-viewer) (6.1.12)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->pypylon-opencv-viewer) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->pypylon-opencv-viewer) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pypylon-opencv-viewer) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pypylon-opencv-viewer) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pypylon-opencv-viewer) (21.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (6.4.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.10.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.11.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (6.0.7)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (22.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (20.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.9/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pypylon-opencv-viewer) (2.8.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (2.0.1)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.9/site-packages (from jupyter->pypylon-opencv-viewer) (6.4.0)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.9/site-packages (from jupyter->pypylon-opencv-viewer) (5.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.5.3)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.1.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (3.3.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.7.1)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pypylon-opencv-viewer) (2.4.7)\n",
      "Requirement already satisfied: qtpy in /opt/conda/lib/python3.9/site-packages (from qtconsole->jupyter->pypylon-opencv-viewer) (1.9.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: pytesseract in /opt/conda/lib/python3.9/site-packages (0.3.7)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from pytesseract) (8.2.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: natsort in /opt/conda/lib/python3.9/site-packages (7.1.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install pypylon\n",
    "!pip install pypylon-opencv-viewer\n",
    "!pip install pytesseract\n",
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import copy\n",
    "import socket\n",
    "import threading\n",
    "import queue\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import NoNorm\n",
    "from matplotlib.colors import Normalize\n",
    "import cv2\n",
    "\n",
    "from pypylon import pylon \n",
    "from pypylon_opencv_viewer import BaslerOpenCVViewer\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import yaml\n",
    "from natsort import natsorted\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_camera(serial_number):\n",
    "    ''' Connects camera specified with its serial number\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    serial_number : string\n",
    "        Camera's serial number.\n",
    "    Returns\n",
    "    -------\n",
    "    camera : object\n",
    "    '''\n",
    "    info = None\n",
    "    for i in pylon.TlFactory.GetInstance().EnumerateDevices():\n",
    "        if i.GetSerialNumber() == serial_number:\n",
    "            info = i\n",
    "            break\n",
    "    else:\n",
    "        print('Camera with {} serial number not found'.format(serial_number))\n",
    "\n",
    "    # VERY IMPORTANT STEP! To use Basler PyPylon OpenCV viewer you have to call .Open() method on you camera\n",
    "    if info is not None:\n",
    "        camera = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateDevice(info)) \n",
    "        camera.Open()\n",
    "        return camera\n",
    "    else:\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    assert os.path.exists(file_path), 'File does NOT exist! (' + file_path + ')'\n",
    "    return cv2.imread(file_path)\n",
    "\n",
    "def save_image(image, file_path):\n",
    "    return cv2.imwrite(file_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_camera_window(*imgs, scale=1):\n",
    "    def print_xy(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONUP:\n",
    "            print('x = %d, y = %d'% (x, y))  \n",
    "        \n",
    "    for i, img in enumerate(imgs, 1):\n",
    "        window_name_id = 'Camera capture' + ' ' + str(i)\n",
    "        \n",
    "        h,w = img.shape[:2]\n",
    "        cv2.namedWindow(window_name_id, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "        cv2.resizeWindow(window_name_id, int(w * scale), int(h * scale))\n",
    "        cv2.setMouseCallback(window_name_id, print_xy)\n",
    "        if len(imgs) > 1:\n",
    "            cv2.moveWindow(window_name_id, (i-1)*int(w * scale), 0)\n",
    "        cv2.imshow(window_name_id, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gray(img_bgr):\n",
    "    ''' Converts image to monochrome\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    if len(img_bgr.shape) == 2:\n",
    "        return img_bgr\n",
    "    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def to_hsv(img_bgr):\n",
    "    ''' Converts image to HSV (hue, saturation, value) color space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    dst = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    return dst\n",
    "\n",
    "def to_rgb(img_bgr):\n",
    "    ''' Converts image to RGB (red, green, blue) color space from BGR.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    dst = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return dst\n",
    "\n",
    "def negative(img):\n",
    "    ''' Converts image to its negative.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    dst = 255 - img\n",
    "    return dst\n",
    "\n",
    "def normalize(img):\n",
    "    '''Normalizes image using min-max normalization from its values to values 0 - 255.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    '''\n",
    "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "def crop(img, tl_x, tl_y, br_x, br_y):\n",
    "    ''' Crops image by added coordinates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    tl_x : int\n",
    "        TOP-LEFT corner's x-coordinate\n",
    "    tl_y : int\n",
    "        TOP-LEFT corner's y-coordinate\n",
    "    br_x : int\n",
    "        BOTTOM-RIGHT corner's x-coordinate\n",
    "    br_y : int\n",
    "        BOTTOM-RIGHT corner's y-coordinate\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    roi = img[tl_y:br_y, tl_x:br_x]\n",
    "    return roi    \n",
    "\n",
    "def crop_by_bounding_rect(img_bin):\n",
    "    ''' Crops binary image by ONE bounding rectangle corresponding to ALL objects in the binary image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output cropped image.\n",
    "    '''\n",
    "    assert len(img_bin.shape) == 2, 'Input image is NOT binary!'\n",
    "    \n",
    "    contours, _  = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    tl_x, tl_y, w, h = cv2.boundingRect(contours[0])\n",
    "    return crop(img_bin, tl_x, tl_y, tl_x+w, tl_y+h)\n",
    "\n",
    "def crop_contour(contour, image):\n",
    "    ''' Crops contour in respect to its bounding rectangle. \n",
    "    It's the fastest method, but could include other parts \n",
    "    of image than just contour if the contour is irregulary shaped.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    contour : numpy.ndarray\n",
    "        Contour that represents the area from image to be cropped. \n",
    "        The bounding rectangle of contour is used.\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output cropped image.\n",
    "    '''\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    return image[y:y+h, x:x+w]\n",
    "\n",
    "def contour_to_image(contour, image, size=None):\n",
    "    ''' Creates new image from the contour. \n",
    "    It's similar to contour cropping but it's not that fast. \n",
    "    It does not suffer from the known error if the contour is irregulary shaped.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    contour : numpy.ndarray\n",
    "        Contour that represents the area from image to be cropped. \n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    size : tuple\n",
    "        Optional size of the created image. \n",
    "        If it's not used, the image's size is the same as the \n",
    "        size of bounding rectangle of the input contour.\n",
    "    Returns\n",
    "    -------\n",
    "    Output cropped image.\n",
    "    '''\n",
    "    if size is None:\n",
    "        _, _, w, h = cv2.boundingRect(contour)\n",
    "        size = (w, h)\n",
    "\n",
    "    assert type(size) is tuple, 'Param size should be a tuple!'\n",
    "    blank = np.zeros_like(image)\n",
    "    half_x = int(size[0] * 0.5)\n",
    "    half_y = int(size[1] * 0.5)\n",
    "\n",
    "    c = get_center(contour)\n",
    "    cv2.drawContours(blank, [contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    return blank[c[1]-half_y:c[1]+half_y, c[0]-half_x:c[0]+half_x].copy()\n",
    "\n",
    "def resize(image, size, method=cv2.INTER_AREA):\n",
    "    ''' Resizes the image to the preffered size.  \n",
    "    Method of resizing is well suited for making the images smaller rather than larger\n",
    "    (cv2.INTER_AREA). For making images larger, use other cv2.INTER_### instead.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        Contour that represents the area from image to be cropped. \n",
    "    size : tuple\n",
    "        New size of the resized image. \n",
    "    method : int\n",
    "        Optional argument. For more information see cv2.INTER_### parameters.\n",
    "    Returns\n",
    "    -------\n",
    "    Output resized image.\n",
    "    '''\n",
    "    assert type(size) is tuple, 'Variable size is NOT a tuple!'\n",
    "    return cv2.resize(image, size, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotated_rectangle(image, idx):\n",
    "    ''' Draws rotated rectangle into the image from indexes of binary image. \n",
    "    You can get the indexes of objects from binary image using cv2.findNonZero().\n",
    "    Input image is not modified.\n",
    "    '''\n",
    "    res = image.copy()\n",
    "    rect = cv2.minAreaRect(idx)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(res, [box], -1, (255, 255, 255), 1)\n",
    "    return res, rect\n",
    "\n",
    "def get_center(contour):\n",
    "    ''' Gets the center of contour in pixels in tuple format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    contour : numpy.ndarray\n",
    "        input contour.\n",
    "    Returns\n",
    "    -------\n",
    "    Center in pixels in tuple format.\n",
    "    '''\n",
    "    M = cv2.moments(contour)\n",
    "    cX = int(M['m10'] / M['m00'])\n",
    "    cY = int(M['m01'] / M['m00'])\n",
    "    \n",
    "    return (cX, cY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_one_threshold(img, threshold):\n",
    "    '''Segments image into black & white using one threshold\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    threshold : int\n",
    "        Pixels with value lower than threshold are considered black, the others white.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    _, dst = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return dst\n",
    "\n",
    "def segmentation_auto_threshold(img):\n",
    "    '''Segments image into black & white using automatic threshold\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    _, dst = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return dst\n",
    "\n",
    "def segmentation_two_thresholds(img, lower, higher):\n",
    "    '''Segments image into black & white using two thresholds\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    lower : int\n",
    "        Pixels with value lower than threshold are considered black, the others white.\n",
    "    higher : int\n",
    "        Pixels with value higher than threshold are considered black, the others white.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    return cv2.inRange(img, min(lower, higher), max(lower, higher))\n",
    "\n",
    "def segmentation_adaptive_threshold(img, size, constant=0):\n",
    "    '''Segments image into black & white using calculated adaptive \n",
    "    threshold using Gaussian function in pixel neighbourhood.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    size : int\n",
    "        Size of used gaussian. Lowest value is 3. Algorithm uses only odd numbers.\n",
    "    constant : int\n",
    "        Value that is added to calculated threshlod. It could be negative as well as zero as well as positive number.\n",
    "    Returns\n",
    "    -------\n",
    "    Output binary image.\n",
    "    '''\n",
    "    if size < 3:\n",
    "        size = 3\n",
    "    elif size % 2 == 0:\n",
    "        size -= 1\n",
    "    return cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, size, int(constant))\n",
    "\n",
    "def apply_mask(img, mask_bin):\n",
    "    '''Masks colored image with binary mask. Output image is just logical AND between two images.'''\n",
    "    return cv2.bitwise_and(img, img, mask = mask_bin)\n",
    "\n",
    "def find_contours(img_bin, min_area=0, max_area=1000000, fill=True, external=True):\n",
    "    '''Finds contours in binary image and filters them using their area. Then it draws binary image\n",
    "    from filtered contours. It counts contours as well.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    min_area : int\n",
    "        Size of contour that is used to filter all smaller contours out.\n",
    "    max_area : int\n",
    "        Size of contour that is used to filter all larger contours out.\n",
    "    Returns\n",
    "    -------\n",
    "    contour_drawn : numpy.ndarray\n",
    "        Output binary image with drawn filled filtered contours.\n",
    "    count : int\n",
    "        Number of found and filtered contours.\n",
    "    contours : list\n",
    "        Found contours.\n",
    "    '''\n",
    "    mode = cv2.RETR_EXTERNAL\n",
    "    if not external:\n",
    "        mode = cv2.RETR_LIST\n",
    "    contours, _  = cv2.findContours(img_bin, mode, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours =  [c for c in contours if cv2.contourArea(c) > min_area and cv2.contourArea(c) < max_area]\n",
    "    thick = cv2.FILLED\n",
    "    if not fill: thick = 2\n",
    "    contour_drawn = cv2.drawContours(np.zeros(img_bin.shape, dtype=np.uint8), contours, -1, color=(255, 255, 255), thickness=thick)\n",
    "    return contour_drawn, len(contours), contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtration_box(img, filter_size):\n",
    "    '''Filters image noise using box blur algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    filter_size : int\n",
    "        Size of box blur filter.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    return cv2.blur(img, (filter_size, filter_size))\n",
    "\n",
    "def filtration_median(img, filter_size):\n",
    "    '''Filters image noise using median algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    filter_size : int\n",
    "        Size of median filter.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    return cv2.medianBlur(img, filter_size)   \n",
    "\n",
    "def filtration_gauss(img, filter_size, sigma_x):\n",
    "    '''Filters image noise using Gaussian blur algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    filter_size : int\n",
    "        Size of Gaussian filter.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    return cv2.GaussianBlur(img, (filter_size, filter_size), sigma_x) \n",
    "\n",
    "def fill_holes(img_bin, close=False, size=5):\n",
    "    '''Fill holes in found contours. It could merge the contour using close input with appropriate size.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    close : boolean\n",
    "        If it should merge contours with missing points using close operation.\n",
    "    size : int\n",
    "        Size of close operation element.\n",
    "    Returns\n",
    "    -------\n",
    "    Output binary image.\n",
    "    '''\n",
    "    if close:\n",
    "        struct = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (size, size))\n",
    "        img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_CLOSE, struct)\n",
    "    res, _, _ = find_contours(img_bin)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fft(image):\n",
    "    ''' Applies FFT on image given.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : 2D array\n",
    "        Image to perform FFT on.\n",
    "    Returns\n",
    "    -------\n",
    "    mag_spec : 2D array\n",
    "        Normalized magnitude spectrum.\n",
    "    fftcls_shift : 2D array\n",
    "        Centered product of FFT.\n",
    "    '''\n",
    "    fftcls = np.fft.fft2(image)\n",
    "    fftcls_shift = np.fft.fftshift(fftcls)\n",
    "    mag_spec = 20*np.log(np.abs(fftcls_shift))\n",
    "    return cv2.normalize(mag_spec,  None, 0, 255, cv2.NORM_MINMAX,cv2.CV_8U), fftcls_shift\n",
    "\n",
    "def inverse_fft(fft_shift, filter_mask=None):\n",
    "    ''' Applies inverse FFT.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fft_shift : 2D array\n",
    "        Shifted computed FFT\n",
    "    filter_mask : 2D array\n",
    "        2D array mask containing 255 and 0 values.\n",
    "    Returns\n",
    "    -------\n",
    "    img_back : 2D array\n",
    "        Image made by inverse FFT.\n",
    "    '''\n",
    "    fftshift = np.copy(fft_shift)\n",
    "    if not filter_mask is None:\n",
    "        fftshift[filter_mask != 255] = 0\n",
    "\n",
    "    f_ishift = np.fft.ifftshift(fftshift)\n",
    "    return np.abs(np.fft.ifft2(f_ishift))\n",
    "\n",
    "def create_filter_mask(size, rows, columns):\n",
    "    ''' Creates a filter mask specified by rows and columns. Specified rows and columns are set to 255, others 0.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    size : tuple\n",
    "        Size of resulting filter mask image.\n",
    "    Returns\n",
    "    -------\n",
    "    filter_mask : 2D array\n",
    "        2D array mask containing 255 and 0 values.\n",
    "    '''\n",
    "    if type(size) != tuple:\n",
    "        raise Exception('Size param must be tuple!')\n",
    "    \n",
    "    filter_mask = np.zeros(size, dtype=np.uint8)\n",
    "    filter_mask[rows] = 255\n",
    "    filter_mask[:,columns] = 255\n",
    "    \n",
    "    return filter_mask\n",
    "\n",
    "def filter_mag_spec(mag_spec, filter_mask):\n",
    "    ''' Filters input spektrum using filter_mask image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mag_spec : 2D array\n",
    "        Image with magnitude spectrum.\n",
    "    filter_mask : 2D array\n",
    "        Filter binary mask image containing values to keep (255) and filter out (0).\n",
    "    Returns\n",
    "    -------\n",
    "    result : 2D array\n",
    "        Vizualization of spectrum after filtering.\n",
    "    '''        \n",
    "    result = np.copy(mag_spec)\n",
    "    result[filter_mask != 255] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(*imgs, scale=1, window_name='Image preview'):\n",
    "    \"\"\" Opens multiple image previews depending on the length of the input *imgs list.\n",
    "    The preview is terminated by pressing the 'q' key.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *imgs : list\n",
    "        Multiple input images which have to be shown.\n",
    "    scale : double\n",
    "        Scale of shown image window.\n",
    "    window_name : Optional[string]\n",
    "        An optional window name.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    See known bug for Mac users\n",
    "    ---------------------------\n",
    "    https://gitlab.fit.cvut.cz/bi-svz/bi-svz/issues/13\n",
    "    \"\"\"\n",
    "    def print_xy(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONUP:\n",
    "            print('x = %d, y = %d'% (x, y)) \n",
    "            \n",
    "    for i, img in enumerate(imgs, 1):\n",
    "        h,w = img.shape[:2]\n",
    "        window_name_id = window_name + ' ' + str(i)\n",
    "        cv2.namedWindow(window_name_id, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "        cv2.resizeWindow(window_name_id, int(w * scale), int(h * scale))\n",
    "        cv2.setMouseCallback(window_name_id, print_xy)\n",
    "        cv2.moveWindow(window_name_id, (i-1)*int(w * scale), 0)\n",
    "\n",
    "    while 1:\n",
    "        for i, img in enumerate(imgs, 1):\n",
    "            cv2.imshow(window_name + ' ' + str(i), img)\n",
    "            \n",
    "        k = cv2.waitKey(0)\n",
    "        \n",
    "        if k == ord('q') or k == ord('Q') or k == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def plot_images(*imgs, titles=[], channels='bgr', normalize=False, ticks_off=True):\n",
    "    assert channels.lower() in ['bgr', 'rgb', 'mono'], 'Possible values for channels are: bgr, rgb or mono!'\n",
    "    \n",
    "#     f = plt.figure(figsize=(30, 20))\n",
    "    width_def = 60\n",
    "    height_def = 60\n",
    "    \n",
    "    width = math.ceil(math.sqrt(len(imgs)))\n",
    "    height = math.ceil(len(imgs) / width)\n",
    "    \n",
    "    height_def = height_def / 5 * width\n",
    "#     print(height_def)\n",
    "    if height_def > 65:\n",
    "        height_def = 65\n",
    "    \n",
    "    f = plt.figure(figsize=(width_def, height_def))\n",
    "    \n",
    "#     print(str(width) + ' , ' + str(height))\n",
    "    for i, img in enumerate(imgs, 1):\n",
    "        ax = f.add_subplot(height, width, i)\n",
    "        if ticks_off:\n",
    "            ax.axis('off')\n",
    "        \n",
    "        if len(titles) != 0:\n",
    "            if len(imgs) != len(titles):\n",
    "                print('WARNING titles lenght is not the same as images lenght!')\n",
    "        \n",
    "            try:\n",
    "                ax.set_title(str(titles[i-1]))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if channels.lower() == 'mono' or img.ndim==2:\n",
    "            if normalize:\n",
    "                norm = Normalize()\n",
    "            else:\n",
    "                norm = NoNorm()\n",
    "            ax.imshow(img, cmap=plt.get_cmap('gray'), norm=norm)\n",
    "        elif channels.lower() == 'rgb':\n",
    "            ax.imshow(img)\n",
    "        else:\n",
    "            ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(img_bin):\n",
    "    '''Detects text in the file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image. White objects on black background.\n",
    "    Returns\n",
    "    -------\n",
    "    Text on image.\n",
    "    '''\n",
    "    # Tesseract works with black objects on white background.\n",
    "    img_bin = negative(img_bin)\n",
    "    return pytesseract.image_to_string(Image.fromarray(img_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_intensity(hue_angle):\n",
    "    '''Converts color angle in HUE definition into intensity value of brightness image in opencv.\n",
    "    https://www.docs.opencv.org/trunk/df/d9d/tutorial_py_colorspaces.html\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hue_angle : int\n",
    "        Angle in HUE definition (0-359).\n",
    "    Returns\n",
    "    -------\n",
    "    Integer value that represents the same HUE value but in opencv brightness image (0-179).\n",
    "    '''\n",
    "    return int(hue_angle * 0.5)\n",
    "\n",
    "def to_angle(hue_intensity):\n",
    "    '''Converts hue intensity value of brightness image in opencv into hue angle in HUE definition.\n",
    "    https://www.docs.opencv.org/trunk/df/d9d/tutorial_py_colorspaces.html\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hue_intensity : int\n",
    "        Intensity value of brightness image (0-179).\n",
    "    Returns\n",
    "    -------\n",
    "    Integer value that represents the HUE angle (0-359).\n",
    "    '''\n",
    "    return hue_intensity * 2\n",
    "\n",
    "def to_3_channels(image):\n",
    "    '''Converts 1 channel image to 3 channels.'''\n",
    "    if len(image.shape) == 3:\n",
    "        raise Exception('Image already has 3 channels! Use it on binary or grayscale image only.')\n",
    "    return cv2.merge([image, image, image])\n",
    "\n",
    "def logical_and(bin_im, bin_mask):\n",
    "    return cv2.bitwise_and(bin_im, bin_mask)\n",
    "\n",
    "def order_points(pts):\n",
    "    '''Sorts the points based on their x-coordinates.'''\n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    # grab the left-most and right-most points from the sorted\n",
    "    # x-roodinate points\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    # now, sort the left-most coordinates according to their\n",
    "    # y-coordinates so we can grab the top-left and bottom-left\n",
    "    # points, respectively\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (bl, tl) = leftMost\n",
    "\n",
    "    # now that we have the top-left coordinate, use it as an\n",
    "    # anchor to calculate the Euclidean distance between the\n",
    "    # top-left and right-most points; by the Pythagorean\n",
    "    # theorem, the point with the largest distance will be\n",
    "    # our bottom-right point\n",
    "    rightMost = rightMost[np.argsort(rightMost[:, 1]), :]\n",
    "    (br, tr) = rightMost\n",
    "\n",
    "    # return the coordinates in top-left, top-right,\n",
    "    # bottom-right, and bottom-left order\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar_warp(img, full_radius=True, inverse=False):\n",
    "    center = (img.shape[0]/2.0, img.shape[1]/2.0)\n",
    "    \n",
    "    if full_radius:\n",
    "        radius = np.sqrt(((img.shape[0]/2.0)**2.0)+((img.shape[1]/2.0)**2.0))\n",
    "    else:\n",
    "        radius = center[0]\n",
    "    \n",
    "    method = cv2.WARP_FILL_OUTLIERS\n",
    "    if inverse: \n",
    "        method += cv2.WARP_INVERSE_MAP\n",
    "    dest = cv2.linearPolar(img, center, radius, method)\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_to_cartesian(img, full_radius=True):\n",
    "    return polar_warp(img, full_radius)\n",
    "\n",
    "def warp_to_polar(img, full_radius=True):\n",
    "    return polar_warp(img, full_radius, True)\n",
    "\n",
    "def rotate(img, angle):\n",
    "    height, width = img.shape[:2]\n",
    "    image_center = (width/2, height/2)\n",
    "\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "\n",
    "    abs_cos = abs(rotation_mat[0,0])\n",
    "    abs_sin = abs(rotation_mat[0,1])\n",
    "\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    rotation_mat[0, 2] += bound_w/2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h/2 - image_center[1]\n",
    "\n",
    "    dest = cv2.warpAffine(img, rotation_mat, (bound_w, bound_h))\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to(src, dst, mask):\n",
    "    '''Python alternative to C++/Java OpenCV's Mat.copyTo().\n",
    "    More: https://docs.opencv.org/trunk/d3/d63/classcv_1_1Mat.html#a626fe5f96d02525e2604d2ad46dd574f'''\n",
    "    locs = np.where(mask != 0) # Get the non-zero mask locations\n",
    "    dst[locs[0], locs[1]] = src[locs[0], locs[1]]\n",
    "    return dst\n",
    "\n",
    "def midpoint(ptA, ptB):\n",
    "    '''Returns the midpoint between two input points.'''\n",
    "    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "def order_points(pts):\n",
    "    '''Sorts the points based on their x-coordinates.'''\n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    # grab the left-most and right-most points from the sorted\n",
    "    # x-roodinate points\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    # now, sort the left-most coordinates according to their\n",
    "    # y-coordinates so we can grab the top-left and bottom-left\n",
    "    # points, respectively\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (bl, tl) = leftMost\n",
    "\n",
    "    # now that we have the top-left coordinate, use it as an\n",
    "    # anchor to calculate the Euclidean distance between the\n",
    "    # top-left and right-most points; by the Pythagorean\n",
    "    # theorem, the point with the largest distance will be\n",
    "    # our bottom-right point\n",
    "    rightMost = rightMost[np.argsort(rightMost[:, 1]), :]\n",
    "    (br, tr) = rightMost\n",
    "\n",
    "    # return the coordinates in top-left, top-right,\n",
    "    # bottom-right, and bottom-left order\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "\n",
    "def rotate_image(image, angle, image_center=None):\n",
    "    \"\"\" Rotates the input image by specified angle.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Image to be rotated.\n",
    "    angle : float\n",
    "        Rotation angle.\n",
    "    image_center : Optional[tuple(int, int)]\n",
    "        Center of rotation.\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Returns the rotated input image by specified angle.\n",
    "    \"\"\"\n",
    "    if image_center is None:\n",
    "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def draw_rotated_text(img, text, point, angle, text_scale, text_color, text_thickness, units='cm'):\n",
    "    img_filled = np.full(img.shape, text_color, dtype=np.uint8)\n",
    "    # create rotated text mask\n",
    "    text_mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "    cv2.putText(text_mask, \"{:.2f} {}\".format(text, units), point, 0, text_scale, (255, 255, 255), text_thickness)\n",
    "    #angle = -angle + 90\n",
    "    text_mask = rotate_image(text_mask, -angle, point)\n",
    "    result = copy_to(img_filled, img.copy(), text_mask)\n",
    "    return result\n",
    "\n",
    "def draw_real_sizes(img, rect, width_text, height_text, lbl_size_scale=2, lbl_color=(0, 0, 255), lbl_thickness=8):\n",
    "    tl, tr, br, bl = order_points(cv2.boxPoints(rect))\n",
    "    mid_pt_width = midpoint(tl, tr)\n",
    "    mid_pt_height = midpoint(tr, br)\n",
    "    \n",
    "    # bottom-left points where labels are drawn\n",
    "    pt_label_first =  (int(mid_pt_width[0] - 10), int(mid_pt_width[1] - 10))\n",
    "    pt_label_second = (int(mid_pt_height[0] + 10), int(mid_pt_height[1]))\n",
    "        \n",
    "    result = draw_rotated_text(img, width_text, pt_label_first, rect[2], lbl_size_scale, lbl_color, lbl_thickness)\n",
    "    result = draw_rotated_text(result, height_text, pt_label_second, rect[2], lbl_size_scale, lbl_color, lbl_thickness)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_image_files(source_dir, output_dir=None):\n",
    "    \"\"\" Reads all images in source_dir and based on they original order, \n",
    "    change their filename to be continuous integer (starting from 0). \n",
    "    Then, they can be easily read by cv2.VideoCapture. Image format is kept.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_dir : string\n",
    "        Input images directory that have to be renamed.\n",
    "    output_dir : Optional[string]\n",
    "        Output directory for renamed files. If not specified, renaming is done inplace in source_dir.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    input_files = []\n",
    "    \n",
    "    for file in os.listdir(source_dir):\n",
    "        if re.match(r'.*(\\.bmp|\\.jpg|\\.png|\\.gif)$', file, re.I):\n",
    "            input_files.append(os.path.join(source_dir, file))\n",
    "\n",
    "    if not input_files:\n",
    "        print('No files were found.')\n",
    "        return\n",
    "    \n",
    "    extension = '.' + input_files[0].split(\".\")[-1]\n",
    "    if output_dir is None:\n",
    "        for i, filename in enumerate(natsorted(input_files)):\n",
    "            os.rename(filename, os.path.join(source_dir, str(i) +  extension))\n",
    "        print(f'Files within {source_dir} were renamed, starting from 0{extension} to {i}{extension}.')\n",
    "    else:\n",
    "        if not os.path.isdir(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "        for i, filename in enumerate(natsorted(input_files)):\n",
    "            shutil.copy(filename, os.path.join(output_dir, str(i) + extension))\n",
    "            \n",
    "        print(f'Files from {source_dir} were renamed and saved to {output_dir}, starting from 0{extension} to {i}{extension}.')\n",
    "\n",
    "def create_file_path(folder, file_name):\n",
    "    '''Easier defined function to create path for filename inside a folder.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : string\n",
    "        Base folder directory in string notation. \n",
    "    file_name : string\n",
    "        File name that should be inside the base folder.\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        Path to the newly created file.\n",
    "    \"\"\"\n",
    "    '''\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "        \n",
    "    return os.path.join(folder, file_name)\n",
    "\n",
    "def camera_calib(input_source, chess_shape, output_calib_file=None, img_show_delay=1):\n",
    "    \"\"\" Browses all images found in input_source and on each image tries to find chessboard corners.\n",
    "    If chessboard corners are found, image corespondences with real world space are added to lists.\n",
    "    Based on these image-world corespondences, camera calibration is made.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_source : string\n",
    "        Input source for cv2.VideoCapture (could be camera source or sequence of saved images where format has to be specified).\n",
    "    chess_shape : tuple\n",
    "        Number of inner corners per a chessboard row and column.\n",
    "    output_calib_file : Optional[string]\n",
    "        Output file where calibration is saved when neccesary.\n",
    "    img_show_delay : int\n",
    "        Delay in ms between shown images.\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        camera matrix and distance coefficients\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        cv2.destroyAllWindows()\n",
    "        raise FileNotFoundError('Capture cannot be opened.')\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((chess_shape[0] * chess_shape[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:chess_shape[0], 0:chess_shape[1]].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, chess_shape)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "            corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    \n",
    "    print('Computing camera matrix...')\n",
    "    rms, camera_matrix, dist_coefs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    \n",
    "    if output_calib_file is not None:\n",
    "        save_camera_calib(output_calib_file, camera_matrix, dist_coefs)\n",
    "\n",
    "    print('\\nRMS:', rms)\n",
    "    print('Camera matrix:\\n', camera_matrix)\n",
    "    print('Distortion coefficients: ', dist_coefs.ravel())\n",
    "    \n",
    "    return camera_matrix, dist_coefs\n",
    "\n",
    "def correct_frame(frame, camera_matrix, dist_coeffs):\n",
    "    \"\"\"Returns undistorted frame.\"\"\"\n",
    "    return cv2.undistort(frame, camera_matrix, dist_coeffs)\n",
    "\n",
    "IDX_CAM_MATRIX = \"camera_matrix\"\n",
    "IDX_DIST_COEFFS = \"dist_coefs\"\n",
    "\n",
    "def load_camera_calib(input_file):\n",
    "    \"\"\" Loads camera calibration from specified input file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : string\n",
    "        Input file with calibration data in YAML format.\n",
    "    Returns\n",
    "    -------\n",
    "    tuple(np.array, np.array)\n",
    "        Returns a tuple where first element is camera matrix array and second element is dist coefficients array. \n",
    "        These arrays might be empty if the file isn't found or in correct format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file, 'r') as stream:\n",
    "            data = yaml.load(stream)\n",
    "            return data[IDX_CAM_MATRIX], data[IDX_DIST_COEFFS]\n",
    "    except (FileNotFoundError, yaml.YAMLError) as exc:\n",
    "        print(f'File {input_file} couldn\\'t be read.')\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "def save_camera_calib(output_file, camera_matrix, dist_coefs):\n",
    "    \"\"\" Saves camera calibration to specified output file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output_file : string\n",
    "        Output file used for storing calibration data in YAML format. Parent directory is created if needed.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    data = {IDX_CAM_MATRIX: camera_matrix, IDX_DIST_COEFFS: dist_coefs}\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    \n",
    "    if not os.path.isdir(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "            \n",
    "    with open(output_file, \"w\") as f:\n",
    "        yaml.dump(data, f)\n",
    "\n",
    "def create_folder_path(base_folder, new_folder_name):\n",
    "    \"\"\" Creates all neccessary folders in the folder tree structure on computer. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_folder : string\n",
    "        Base folder directory in string notation. \n",
    "    output_dir : string\n",
    "        Folder name that should be inside the base folder.\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        Path to the newly created folder.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(base_folder):\n",
    "        os.mkdir(base_folder)\n",
    "            \n",
    "    path = os.path.join(base_folder, new_folder_name)        \n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)      \n",
    "            \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionless descriptors\n",
    "class ShapeDescriptors:\n",
    "    def form_factor(area, perimeter):\n",
    "        return (4 * np.pi * area) / (perimeter * perimeter)\n",
    "    \n",
    "    def roundness(area, max_diameter):\n",
    "        return (4 * area) / (np.pi * max_diameter * max_diameter)\n",
    "    \n",
    "    def aspect_ratio(min_diameter, max_diameter):\n",
    "        return min_diameter / max_diameter;\n",
    "    \n",
    "    def convexity(perimeter, convex_perimeter):\n",
    "        return convex_perimeter / perimeter\n",
    "    \n",
    "    def solidity(area, convex_area):\n",
    "        return area / convex_area\n",
    "    \n",
    "    def compactness(area, max_diameter):\n",
    "        return np.sqrt(4 / np.pi * area) / max_diameter;\n",
    "        \n",
    "    def extent(area, bounding_rectangle_area):\n",
    "        return area / bounding_rectangle_area;\n",
    "\n",
    "# piatost\n",
    "def form_factor(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    return ShapeDescriptors.form_factor(cv2.contourArea(conts[0]), cv2.arcLength(conts[0], True))\n",
    "\n",
    "# Kulatost\n",
    "def roundness(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    area = cv2.contourArea(conts[0])\n",
    "    _,radius = cv2.minEnclosingCircle(conts[0])\n",
    "    r = ShapeDescriptors.roundness(area, 2*radius)\n",
    "    if r > 1: r = 1\n",
    "    return r\n",
    "\n",
    "# Pomr stran\n",
    "def aspect_ratio(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    dims = cv2.minAreaRect(conts[0])[1]\n",
    "    min_diameter = min(dims)\n",
    "    max_diameter = max(dims)\n",
    "    return ShapeDescriptors.aspect_ratio(min_diameter, max_diameter)\n",
    "    \n",
    "# Konvexita, vypouklost\n",
    "def convexity(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    hull = cv2.convexHull(conts[0], None, True, True)\n",
    "    per = cv2.arcLength(conts[0], True)\n",
    "    conv_per = cv2.arcLength(hull, True)\n",
    "    r = ShapeDescriptors.convexity(per, conv_per)\n",
    "    if r > 1: r = 1\n",
    "    return r \n",
    "\n",
    "# Plnost, celistvost\n",
    "def solidity(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    hull = cv2.convexHull(conts[0], None, True, True)\n",
    "    area = cv2.contourArea(conts[0])\n",
    "    conv_area = cv2.contourArea(hull)\n",
    "    r = ShapeDescriptors.solidity(area, conv_area)\n",
    "    if r > 1: r = 1\n",
    "    return r \n",
    "    \n",
    "# Kompaktnost, hutnost\n",
    "def compactness(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    area = cv2.contourArea(conts[0])\n",
    "    max_diameter = max(cv2.minAreaRect(conts[0])[1])\n",
    "    r = ShapeDescriptors.compactness(area, max_diameter)\n",
    "    if r > 1: r = 1\n",
    "    return r \n",
    "    \n",
    "# Dosah, rozmrnost\n",
    "def extent(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    area = cv2.contourArea(conts[0])\n",
    "    w, h = cv2.minAreaRect(conts[0])[1]\n",
    "    return ShapeDescriptors.extent(area, w*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(grabbed_images_folder_path, chess_shape):\n",
    "    reindex_image_files(grabbed_images_folder_path)\n",
    "    images_format = '%01d.png'\n",
    "    calibration_file_name = 'config.yaml'\n",
    "    output_calib_file_path = create_file_path(grabbed_images_folder_path, calibration_file_name)\n",
    "    return camera_calib(create_file_path(grabbed_images_folder_path, images_format), chess_shape=chess_shape,output_calib_file=output_calib_file_path)\n",
    "\n",
    "def fix_camera_picture(image, camera_matrix, dist_coefs):\n",
    "    return correct_frame(image, camera_matrix, dist_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_histogram(image, brg = False):\n",
    "    color = ('r','g','b')\n",
    "    if brg:\n",
    "        color = ('b','r','g')\n",
    "    for i,col in enumerate(color):\n",
    "        histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "        plt.plot(histr,color = col)\n",
    "        plt.xlim([0,256])\n",
    "        plt.ylim([0,8000])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colored_square(size=30, rgb_color=(0, 0, 0)):\n",
    "    image = np.zeros((size, size, 3), np.uint8)\n",
    "    color = tuple(reversed(rgb_color))\n",
    "    image[:] = color\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_points(image, points, size):\n",
    "    box_points_drawn = image.copy()\n",
    "    for p in points:\n",
    "        cv2.circle(box_points_drawn,(p[0],p[1]), size, (0,0,255), -1)\n",
    "    return box_points_drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns hue values min and max for segmentation. Select starting point in image start=(num1, num2) and it returns lower and upper bound.\n",
    "\n",
    "def find_hsv_minmax(hsv_image, start, scope):\n",
    "    low = [255, 255, 255]\n",
    "    high = [0, 0, 0]\n",
    "    for j in range(start[0] - int(scope/2), start[0] + int(scope/2 + scope%2)):\n",
    "        for i in range(start[1] - int(scope/2), start[1] + int(scope/2 + scope%2)):\n",
    "            if low[0] > hsv_image[i][j][0]:\n",
    "                low[0] = hsv_image[i][j][0]\n",
    "            if low[1] > hsv_image[i][j][1]:\n",
    "                low[1] = hsv_image[i][j][1]\n",
    "            if low[2] > hsv_image[i][j][2]:\n",
    "                low[2] = hsv_image[i][j][2]\n",
    "            \n",
    "            if high[0] < hsv_image[i][j][0]:\n",
    "                high[0] = hsv_image[i][j][0]\n",
    "            if high[1] < hsv_image[i][j][1]:\n",
    "                high[1] = hsv_image[i][j][1]\n",
    "            if high[2] < hsv_image[i][j][2]:\n",
    "                high[2] = hsv_image[i][j][2]\n",
    "    return low, high\n",
    "\n",
    "# lower_bound, upper_bound = find_hsv_bounds(image, indices, 5)\n",
    "def find_hsv_bounds(image, points, scope, point_area=5):\n",
    "    plot_images(highlight_points(image, points, point_area))\n",
    "    low = [255, 255, 255]\n",
    "    high = [0, 0, 0]\n",
    "    hsv_image = to_hsv(image)\n",
    "    for point in points:\n",
    "        l, h = find_hsv_minmax(hsv_image, point, scope)\n",
    "        if low[0] > l[0]:\n",
    "            low[0] = l[0]\n",
    "        if low[1] > l[1]:\n",
    "            low[1] = l[1]\n",
    "        if low[2] > l[2]:\n",
    "            low[2] = l[2]\n",
    "\n",
    "        if high[0] < h[0]:\n",
    "            high[0] = h[0]\n",
    "        if high[1] < h[1]:\n",
    "            high[1] = h[1]\n",
    "        if high[2] < h[2]:\n",
    "            high[2] = h[2]\n",
    "    print(f'lower bound: {low}')\n",
    "    print(f'upper bound: {high}')\n",
    "    return tuple(low), tuple(high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = create_hsv_mask(image, lower_bound, upper_bound, tolerance=10)\n",
    "def create_hsv_mask(image, low, high, tolerance=10):\n",
    "    l1 = int(max(0, low[0]-tolerance))\n",
    "    l2 = int(max(0, low[1]-tolerance))\n",
    "    l3 = int(max(0, low[2]-tolerance))\n",
    "\n",
    "    u1 = int(min(255, high[0]+tolerance))\n",
    "    u2 = int(min(255, high[1]+tolerance))\n",
    "    u3 = int(min(255, high[2]+tolerance))\n",
    "    img_patterns_color = to_hsv(image)\n",
    "    return cv2.inRange(img_patterns_color, (l1, l2, l3),(u1, u2, u3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contours = get_contours(mask, number_of_contours=5, min_area=1)\n",
    "def get_contours(mask, number_of_contours=1, min_area=0, max_area=-1):\n",
    "    contours, _  = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    contours = [contour for contour in contours if cv2.contourArea(contour) >= min_area]\n",
    "    if max_area > min_area:\n",
    "        contours = [contour for contour in contours if cv2.contourArea(contour) <= max_area]\n",
    "    print(f'Found {len(contours)} contour(s). Returning sorted from largest: {number_of_contours}')\n",
    "    return contours[:number_of_contours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = get_image_from_contour([contour[0]], image, False)[0]\n",
    "def get_image_from_contour(contours, image, cut=False):\n",
    "    blank = np.zeros_like(image)\n",
    "    contour_image = cv2.drawContours(blank, contours, -1, (255, 255, 255), cv2.FILLED)\n",
    "    if not cut:\n",
    "        return [contour_image]\n",
    "    contour_images = []\n",
    "    for contour in contours:\n",
    "        blank = np.zeros_like(image)\n",
    "        contour_image = to_gray(cv2.drawContours(blank, [contour], -1, (255, 255, 255), cv2.FILLED))\n",
    "        contour_images.append(crop_by_bounding_rect(contour_image))\n",
    "    return contour_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_erode = erode(mask, get_square_kernel(40))\n",
    "def erode(mask, kernel):\n",
    "    return cv2.erode(mask, kernel, iterations=1)\n",
    "\n",
    "# mask_dilate = dilate(mask, get_square_kernel(65))\n",
    "def dilate(mask, kernel):\n",
    "    return cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "def get_square_kernel(size):\n",
    "    return np.ones((size,size), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_images(highlight_contour(contours, image))\n",
    "def highlight_contour(contours, image):\n",
    "    contour_drawn = cv2.drawContours(image.copy(), contours, -1, color=(255, 0, 0), thickness=5)\n",
    "    return contour_drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rect_size_from_contour(contour, scale):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    if abs(rect[2]) < 45:\n",
    "        shape_height, shape_width = rect[1]   \n",
    "        return shape_width*scale, shape_height*scale\n",
    "    else: \n",
    "        shape_width, shape_height = rect[1] \n",
    "        return shape_width*scale, shape_height*scale\n",
    "\n",
    "# plot_images(get_rect_sizes(image, contours, 0.017167381974248927))\n",
    "def get_rect_sizes(image, contours, real_image_ratio):\n",
    "    image_with_measurement = image.copy()\n",
    "    for contour in contours:\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        if abs(rect[2]) < 45:\n",
    "            shape_height, shape_width = rect[1]   \n",
    "        else: \n",
    "            shape_width, shape_height = rect[1] \n",
    "\n",
    "        real_width = (shape_width*real_image_ratio) \n",
    "        real_height = (shape_height*real_image_ratio) \n",
    "\n",
    "        cv2.drawContours(image_with_measurement, [contour], -1, color=(255, 0, 0 ), thickness=5)\n",
    "        image_with_measurement = draw_real_sizes(\n",
    "            image_with_measurement,\n",
    "            rect,\n",
    "            real_height,\n",
    "            real_width,\n",
    "            lbl_size_scale=.7,\n",
    "            lbl_color=(0, 0, 255),\n",
    "            lbl_thickness=1\n",
    "        )\n",
    "    return image_with_measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(original_image, a_pos, b_pos):\n",
    "    image = copy.deepcopy(original_image)\n",
    "    a_pos = (int(a_pos[0]), int(a_pos[1]))\n",
    "    b_pos = (int(b_pos[0]), int(b_pos[1]))\n",
    "    cv2.line(image, a_pos, b_pos, (0, 0, 255), 5)\n",
    "    return image\n",
    "\n",
    "# contour_area_image = draw_number(contour_area_image, area, get_center(contours[2]), 'cm^2')\n",
    "def draw_number(original_image, number, position, units='cm'):\n",
    "    image = copy.deepcopy(original_image)\n",
    "    position = (int(position[0]), int(position[1]))\n",
    "    image = draw_rotated_text(\n",
    "        image, \n",
    "        number, \n",
    "        position, \n",
    "        0, \n",
    "        1, \n",
    "        (255, 0, 0), \n",
    "        2,\n",
    "        units\n",
    "    )\n",
    "    return image\n",
    "\n",
    "# dist_cont_image, distance, point_a, point_b = get_contours_distances(image, [contours[0], contours[1]], 0.017167381974248927)\n",
    "def get_contours_distances(original_image, contours, ratio):\n",
    "    image = copy.deepcopy(original_image)\n",
    "    indices = copy.deepcopy(contours)\n",
    "    contour_map = list(itertools.combinations(indices , 2))\n",
    "\n",
    "    for comb in contour_map:\n",
    "        dist = None\n",
    "        a_pos = []\n",
    "        b_pos = []\n",
    "        for a in comb[0]:\n",
    "            for b in comb[1]:\n",
    "                x1 = a[0][0]\n",
    "                y1 = a[0][1]\n",
    "                x2 = b[0][0]\n",
    "                y2 = b[0][1]\n",
    "                dx = x2 - x1\n",
    "                dy = y2 - y1\n",
    "                current_dist = (dx * dx + dy * dy) ** 0.5\n",
    "                if dist is not None:\n",
    "                    if dist > current_dist:\n",
    "                        dist = current_dist\n",
    "                        a_pos = a[0]\n",
    "                        b_pos = b[0]\n",
    "                else:\n",
    "                    dist = current_dist\n",
    "                    a_pos = a[0]\n",
    "                    b_pos = b[0]\n",
    "        image = draw_line(image, a_pos, b_pos)\n",
    "        image = draw_number(\n",
    "            image, \n",
    "            dist*ratio, \n",
    "            (\n",
    "                int((a_pos[0] + b_pos[0])/2), \n",
    "                int((a_pos[1] + b_pos[1])/2)\n",
    "            )\n",
    "        )\n",
    "    return image, dist*ratio, a_pos, b_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_contour_area(contours[2], image, 0.0002889)\n",
    "def get_contour_area(contour, image, scale):\n",
    "    area = cv2.contourArea(contour)\n",
    "    return area*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour = get_contour_containing_point(contours, image, [(1151, 321), (300, 380)])\n",
    "def get_contour_containing_point(contours, image, points):\n",
    "    found_contours = []\n",
    "    plot_images(highlight_points(image, points, 5))\n",
    "    for point in points:\n",
    "        point = [int(point[0]), int(point[1])]\n",
    "        for contour in contours:\n",
    "            mask = get_image_from_contour([contour], image, False)[0]\n",
    "            if (mask[point[1]][point[0]] != [0, 0, 0]).all():\n",
    "                found_contours.append(contour)\n",
    "    return found_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_contour_similarity_difference(contour_a, contour_b, key_a, key_b)\n",
    "def get_contour_similarity_difference(contour_a, contour_b, image_a, image_b):\n",
    "    functions = [form_factor, roundness, aspect_ratio, convexity, solidity, compactness, extent]\n",
    "    descriptions_a = []\n",
    "    descriptions_b = []\n",
    "    image_a = get_image_from_contour([contour_a], image_a, cut=True)[0]\n",
    "    image_a = to_gray(image_a)\n",
    "    image_b = get_image_from_contour([contour_b], image_b, cut=True)[0]\n",
    "    image_b = to_gray(image_b)\n",
    "    for func in functions:\n",
    "        descriptions_a.append(func(image_a))\n",
    "        descriptions_b.append(func(image_b))\n",
    "    difference = np.linalg.norm(np.array(descriptions_a) - np.array(descriptions_b))\n",
    "    return difference\n",
    "\n",
    "# sorted_contours = sort_contours_by_similarity(contours[0], contours, image)\n",
    "def sort_contours_by_similarity(ref_contour, contours, image):\n",
    "    contour_list = []\n",
    "    cont = []\n",
    "    diff = []\n",
    "    for contour in contours:\n",
    "        similarity = get_contour_similarity_difference(ref_contour, contour, image, image)\n",
    "        contour_list.append([similarity, contour])\n",
    "    return [(k, v) for k, v in sorted(contour_list, key=lambda item: item[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_union(mask_erode, mask_dilate)\n",
    "def mask_union(mask_a, mask_b):\n",
    "    return cv2.bitwise_or(mask_a, mask_b)\n",
    "\n",
    "# mask_intersect(mask_erode, mask_dilate)\n",
    "def mask_intersect(mask_a, mask_b):\n",
    "    return cv2.bitwise_and(mask_a, mask_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
